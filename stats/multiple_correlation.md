Multiple correlation

The coefficient of multiple correlation is a measure of how well 
    a given variable 
    can be predicted using 
    a linear function of 
    a set of other variables. 
    
It is the correlation between the variable's values and the best predictions that can be computed linearly from the predictive variables.

The coefficient of multiple correlation takes values between 0 and 1; 
    a higher value indicates a better predictability of the dependent variable from the independent variables, 
    with a value of 1 indicating that the predictions are exactly correct and a value of 0 indicating that 
        no linear combination of the independent variables is a better predictor than is the fixed mean of the dependent variable.

The coefficient of multiple correlation is computed as the square root of the coefficient of determination, 
    but under the particular assumptions that an intercept is included and that the best possible linear predictors are used, 
    whereas the coefficient of determination is defined for more general cases, 
        including those of nonlinear prediction and 
        those in which the predicted values have not been derived from a model-fitting procedure. 

Definition
    The coefficient of multiple correlation, denoted R, is 
        a scalar that is 
        defined as the Pearson correlation coefficient between 
            the predicted and 
            the actual values of 
        the dependent variable in a linear regression model that includes an intercept. 

The squared coefficient of multiple correlation can also be computed as 
    the fraction of variance of the dependent variable that is explained by the independent variables, 
        which in turn is 1 minus the unexplained fraction. 
The unexplained fraction can be computed as 
    the sum of squared residuals — that is, the sum of the squares of the prediction errors — divided by 
    the sum of the squared deviations of the values of the dependent variable from its expected value. 

http://mtweb.mtsu.edu/stats/regression/level3/multicorrel/multicorrcoef.htm

The Sample Multiple Correlation Coefficient, R, is a 
    measure of the strength of the association between the independent (explanatory) variables and the one dependent (prediction) variable.


The squared coefficient of multiple correlation can also be computed as the fraction of variance of the dependent variable that is explained by the independent variables, which in turn is 1 minus the unexplained fraction. The unexplained fraction can be computed as the sum of squared residuals—that is, the sum of the squares of the prediction errors—divided by the sum of the squared deviations of the values of the dependent variable from its expected value.

Interpretation of R

    Strength of the Association:  The strength of the association is measured by the sample Multiple Correlation Coefficient, R.  R can be any value from 0 to +1.   
        The closer R is to one, the stronger the linear association is.  
        If R equals zero, then there is no linear association between the dependent variable and the independent variables.  
     
    Unlike the simple correlation coefficient, r, which tells both the strength and direction of the association, R tells only the strength of the association.  
    R is never a negative value.  
    This can be seen from the formula below, since the square root of this value indicates the positive root.

    R value
    1: perfect linear relationship
    0: no linear relationship
    0.9: strong association
    0.5: moderate association
    0.25: weak association